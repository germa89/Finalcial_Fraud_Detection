{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Title:** Fraud Detection on Credit Card records using Random Forest.   \n",
    "**Author:** German Martinez-Ayuso   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A not very formal, neither comprehensive guide to the application of the gradient boosted decision trees to the detection of fraud in finance.** \n",
    "\n",
    "\n",
    "Inspiration article: _\"Credit Card Fraud Detection using Autoencoders in Keras | TensorFlow for Hackers (Part VII)\"_ By Venelin Valkov. [Link](https://www.curiousily.com/posts/credit-card-fraud-detection-using-autoencoders-in-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Nowadays having a credit or debit card for shopping online seems like mandatory, specially during quarantine. However everybody (at least me!) feels a bit unsecured when they input their card numbers on a website. There are many risks out there, identity fraud, theft of bank details, etc. \n",
    "Fortunately many banks are catching up with fraud detection applying machine learning techniques. In this article/gist we are going to demonstrate how we can use boosted decision trees to detect fraud in credit cards records.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree is decision tool whose structure resemble a tree. Each of the nodes of this structure represents a \"test\" (or evaluation of an activation function). Using the results of these test, the classification rules are obtained which goes from the root (input) to the leaves (outputs). \n",
    "\n",
    "One example of decision tree is the Galton machine:\n",
    "\n",
    "|![Galton machine](galton_machine.gif)| \n",
    "|:------:|\n",
    "|   [Galton machine](https://en.wikipedia.org/wiki/File:Galton_box.webm) |\n",
    "|From [Wikipedia-Beam machine](https://en.wikipedia.org/wiki/Bean_machine)  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the pegs is a test where the ball will be driven to one of the sides. Since all the pegs and balls are equal, the probability of the ball going to one side or another is the same. Since it is the same, the balls will tend to be closer to the center because the probability of them going to the extremes is lower. This machine generate a distribution of the balls which corresponds to the \"**normal distribution**\". \n",
    "\n",
    "\n",
    "\n",
    "| ![Galton board](galton_board.pNg) | \n",
    "|:------:|\n",
    "|   Galton representation  |\n",
    "| Copyright : Peter Hermes Furian. [123RF.com](https://www.123rf.com/photo_79407706_stock-vector-the-mathematics-of-the-galton-board-with-normal-distribution-and-gaussian-bell-curve-also-quincunx-b.html) |\n",
    "\n",
    "The decision trees present several advantages. The main one is that they are easy to understand and interpret hence these models are widely applied in order to obtain a good understanding of the underlying model.\n",
    "\n",
    "\n",
    "## Decision Tree Structure\n",
    "The decision trees are composed of:\n",
    "- Nodes. Where the branches growth from. Here is where the tests are applied.\n",
    "- Branches. They represents the links between nodes.\n",
    "- Leaves. They are the final output at the end of the branches. They might not be applied any tests. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Decision Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost is the solution for the optimization of assemblies of decision trees. It is based on the concept that decision trees can be considered as a function which can be optimized using gradient techniques as any common function. \n",
    "This optimization would be \"measured\" using a loss function. \n",
    "This function is a measure of the error in the predicted values compared with the real values in the training set.\n",
    "\n",
    "The algorithm uses the next inputs:\n",
    "\n",
    "- Training set: $\\{(x_i, y_i)\\}^n_{i=1}$ \n",
    "- Differentiable loss function: $L(y,F(x))$ \n",
    "- Maximum number of iterations: $M$\n",
    "\n",
    "and follows the next steps (From Wikipedia):\n",
    "\n",
    "1. Initialize the model with random values.\n",
    "\n",
    "$$F_0(x) = \\arg \\min \\sum^n_{i=1} L(y_i, \\gamma)$$\n",
    "\n",
    "2. For m=1 to M:  \n",
    "\n",
    "    2.1. Compute so-called pseudo-residuals:\n",
    "    $$ r_{im} = - \\left[ \\dfrac{\\partial L(y_i,F(x_i))}{\\partial F(x_i)} \\right]_{F(x) = F_{m-1}(x)} \\hspace{3ex} \\text{for i = 1,  ..., n}$$   \n",
    "    \n",
    "    2.2. Fit a base learner (or weak learner e.g. tree) $h_m(x)$ to pseudo-residuals, i.e. train it using the training set.     \n",
    "    \n",
    "    2.3. Compute multiplier $\\gamma_m$ by solving the one-dimensional optimization problem:\n",
    "    $$ \\gamma_m = \\arg \\min \\sum^n_{i=1} L(y_i, F_{m-1}(x_i) + \\gamma h_m(x_i))$$   \n",
    "    \n",
    "    2.4. Update the model:\n",
    "    $$ F_m(x) = F_{m-1}(x) + \\gamma_m h_m(x)$$\n",
    "\n",
    "3. Output $F_M(x)$.\n",
    "\n",
    "This is as it is explained in Wikipedia. However in a more simplistic way, this procedure could be explained as:\n",
    "\n",
    "1. Initialize the model with random values ($x_0$).\n",
    "2. Start iterations until maximum number of iterations is reached. \n",
    "\n",
    "    2.1. Calculate the increments in the loss function for the values ($x_m$).  \n",
    "    2.2. Train the decision trees ($h_m(x)$) to fit the increments.  \n",
    "    2.3. Obtain $\\gamma$ from the optimization problem given the trained trees.  \n",
    "    2.4. Update the model ($F_m(x)$).   \n",
    "    \n",
    "It should be noticed that the decision trees are trained on the residual, hence their results $h_m(x)$ are added to the solution in the previous iteration $F_{m-1}(x)$ multiplied by $\\gamma_m$. \n",
    "\n",
    "\n",
    "## Avoiding overfitting.\n",
    "\n",
    "Overfitting is the what happens when the model tends to replicate very accurate the training set but it does not perform well on new data. \n",
    "This is considered as a reduction in the generality of the model and it is addressed by using regularization techniques:\n",
    "\n",
    "### Shrinkage\n",
    "This consists in adding another multiplier to the $\\gamma_m$ coefficient:  \n",
    "\n",
    "$$ F_m(x) = F_{m-1}(x) + \\nu \\gamma_m h_m(x)  \\hspace{3ex} 0 < \\nu \\leq 1$$   \n",
    "\n",
    "where $\\nu$ is called \"learning rate\". \n",
    "\n",
    "This improves substantially the performance the model. Empirically it is demonstrated that values of $\\nu$ lower than 0.1 are the best. \n",
    "\n",
    "\n",
    "### Stochastic gradient boosting\n",
    "\n",
    "Stochastic gradient boosting take the idea from the bootstrap aggregation (\"bagging\") method. \n",
    "The idea consists on train each of the trees ($h_m(x)$) in a subset of the training set randomly generated without replacement.\n",
    "It has been observed that this improve substantially the model accuracy. \n",
    "The subsample size is represented as a fraction $f$ of the total set. If $f=1$ this improvement is not applied. Practically it has been observed that for moderate or small size dataset, the optimal $f$ values are between 0.5 and 0.8.\n",
    "Since the subsets are smaller, there is generally an improvement in the training speed. \n",
    "\n",
    "This approach might leave out some observations when building the learners (trees). These observation can be used as a validation inside the scheme hence it is not needed a validation set. The error between these leave-out observations and the model predictions is called \"out-of-bag error. \n",
    "\n",
    "\n",
    "### Number of observation in leaves.\n",
    "Ensuring that there is, at least, a minimum number of observations in each of the leaves of the trees is another way to help to regularize the model. \n",
    "\n",
    "\n",
    "### Penalize tree complexity\n",
    "The complexity of the tree is measured as the number of leaves. Using a suitable pruning approach it might help to reduce the number of leaves by removing leaves or branches that do not contribute to reduce the loss by a threshold. \n",
    "\n",
    "\n",
    "--  \n",
    "**REFERENCES:**   \n",
    "\n",
    "1. [Wikipedia-Decision Tree](https://en.wikipedia.org/wiki/Decision_tree)   \n",
    "2. [Wikipedia-Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting)   \n",
    "3. [Wikipedia-Receiver operating characteristics](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of XGBoost to Finance Fraud detection\n",
    "\n",
    "## Dataset: Credit card transfers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables are not defined, then we are going to use a black-input approach. We won't do an exploratory analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    df.drop('Class',axis=1),\n",
    "                                    df['Class'],\n",
    "                                    test_size=0.3,\n",
    "                                    train_size=0.7,\n",
    "                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score as measure_roc_auc\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a random search algorithm which will find the optimal values for the model parameters. \n",
    "Other option is to use a grid search, however this grid search is frequently more time-consuming than the random search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1d0178445503>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#opt_xgb.fit(X_train, y_train) #Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nThe AUC score is {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_bin=16)\n",
    "\n",
    "# Space search for the parameters.\n",
    "prams={\n",
    "    'learning_rate':[0.01,0.033,0.063,0.1], #Step size shrinkage used to prevent overfitting. Range is [0,1]\n",
    "    'n_estimators':[100,200,500],        #Number of trees you want to build.\n",
    "    'max_depth':[3,5],                          #The maximum depth of a tree\n",
    "    'colsample_bytree':[0.1,0.3,0.5],            #Denotes the fraction of columns to be randomly samples for each tree.\n",
    "    'subsample':[0.1,0.3,0.5]                    #Denotes the fraction of observations to be randomly samples for each tree.\n",
    "}\n",
    "\n",
    "# prams={\n",
    "#     'learning_rate':[0.05], #Step size shrinkage used to prevent overfitting. Range is [0,1]\n",
    "#     'n_estimators':[100],        #Number of trees you want to build.\n",
    "#     'max_depth':[3],                          #The maximum depth of a tree\n",
    "#     'colsample_bytree':[0.1],            #Denotes the fraction of columns to be randomly samples for each tree.\n",
    "#     'subsample':[0.1]                    #Denotes the fraction of observations to be randomly samples for each tree.\n",
    "# }\n",
    "\n",
    "\n",
    "#RandomizedSearchCV search for the optimal set of hyperparameters\n",
    "opt_xgb=RandomizedSearchCV(xgb,\n",
    "                              param_distributions=prams,\n",
    "                              verbose=2,\n",
    "                              n_iter=20,\n",
    "                              cv=10,\n",
    "                              scoring='roc_auc',\n",
    "                              n_jobs=2 # To speed up calculations\n",
    "                             );\n",
    "\n",
    "#opt_xgb.fit(X_train, y_train) #Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the model for later sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'opt_xgb' (RandomizedSearchCV)\n",
      "Stored 'df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# Saving\n",
    "%store opt_xgb df \n",
    "# backup = pd.HDFStore('backup.h5')\n",
    "# backup['df'] = df\n",
    "# backup['opt_xgb'] = opt_xgb\n",
    "# backup.close()\n",
    "\n",
    "#load \n",
    "# %store -r opt_xgb df \n",
    "# backup = pd.HDFStore('backup.h5')\n",
    "# df = backup['df']\n",
    "# opt_xgb = backup['opt_xgb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing model best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.1,\n",
      " 'learning_rate': 0.05,\n",
      " 'max_depth': 3,\n",
      " 'n_estimators': 100,\n",
      " 'subsample': 0.1}\n",
      "\n",
      "The AUC score is 0.9612704724230839\n"
     ]
    }
   ],
   "source": [
    "pprint(opt_xgb.best_params_)\n",
    "print(\"\\nThe AUC score is {}\".format(opt_xgb.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the test values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test AUC for training data is: 0.962289\n"
     ]
    }
   ],
   "source": [
    "predict_y = opt_xgb.predict_proba(X_test)\n",
    "accur_training = measure_roc_auc(y_test, predict_y[:, 1])\n",
    "\n",
    "print(\"The test AUC for training data is: {:0.6f}\".format(accur_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC score is 0.962289 on the test samples. The AUC score is the area under the curve ROC which is the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = roc_curve(y_test, predict_y[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# # Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "from xgboost import plot_tree\n",
    "\n",
    "model = opt_xgb.best_estimator_\n",
    " \n",
    "plot_importance(model, importance_type='gain', max_num_features=10); "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
